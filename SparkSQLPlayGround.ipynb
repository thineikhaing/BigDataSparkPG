{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1d0Uf-SLpEe9vf4M0mi21PSTtM3_UZAzt",
      "authorship_tag": "ABX9TyO9805j4FoYxYvxUUw6YWGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thineikhaing/BigDataSparkPG/blob/main/SparkSQLPlayGround.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation**\n",
        "The first step involves installing pyspark. The next step is to install findspark library."
      ],
      "metadata": {
        "id": "WXBRhZ_X4Gaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VsDUMHwI3fgs"
      },
      "outputs": [],
      "source": [
        "# install pyspark using pip\n",
        "!pip install --ignore-install -q pyspark\n",
        "# install findspark using pip\n",
        "!pip install --ignore-install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "You can use the drive module from google.colab to mount your entire Google Drive to Colab by executing the below code. This will provide us with an authentication link to connect to Google Drive. Choose the Google account whose Drive you want to mount. Allow Google Drive Stream access to your Google Account."
      ],
      "metadata": {
        "id": "mTaWdLlw4hm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to read in data from a text file, first upload the data file into your google drive and then mount your google drive onto colab\n",
        "from google.colab import drive\n",
        "# to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD5sdtor4s1F",
        "outputId": "3fb1b94a-c722-4ef1-9141-0f00c9aed41e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the sample spark df"
      ],
      "metadata": {
        "id": "gT-wsMIY6BrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day3 Workshop4**\n",
        "\n",
        "Exercise1:\n",
        "\n",
        "Using Dataframes and SparkSQL and working on Rebu Case study files mentioned above, write Spark SQL\n",
        "for the following:\n",
        "\n",
        "A. Data retrieval using Spark SQL\n",
        "1. Retrieve all Driver data (use Drivers.CSV)\n",
        "2. Retrieve all Taxis and display the data in ascending order of Taxi License Plate number.\n",
        "3. Retrieve all Limosine Taxies. You should display only the Taxi Number, Taxi Type, and Taxi\n",
        "Colour.\n",
        "4. Retrieve all 4 seater Premier taxis.\n",
        "\n",
        "B. Aggregation and Statistical Queries (use BEAD_Rebu_TripData.CSV)\n",
        "Determine the average distance per trip based on ALL trips in the month of January 2024.\n",
        "Find the total fares collected grouped by Taxi Type Maxi Cab\n",
        "\n",
        "C. Analytics Questions\n",
        "7. Determine the Average Occupancy i.e., (Number of Passengers / Passenger Capacity) for\n",
        "Standard Taxis.\n",
        "8. Determine Fares Collected by Day of the Week (ie., Sun, Mon, Tue) for the month of Jan 2024.\n",
        "9. Prepare a Tabulation report showing total revenue against the two dimensions Hour of the\n",
        "day AND Day of the Week.\n",
        "10. Compare the total number of trips per day made by all taxis in weekends vs the total number\n",
        "of trips made per day during weekdays in the month of Jan 2024.\n",
        "\n",
        "D. Multiple Entities Joining and multiple formats joined in a DataFrame\n",
        "11. Determine the total fares paid by all Gold Status Passengers in the month of Jan 2024. What\n",
        "percentage does this make from the total fares for all customers in month of Jan 2024."
      ],
      "metadata": {
        "id": "TUE02aOJPnyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import avg, sum, col, month, year, to_date, dayofweek\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RebuCaseStudy\").getOrCreate()\n",
        "\n",
        "drivers_df = spark.read.option(\"header\", \"true\").csv(\"/content/drive/My Drive/BEAD_DATA/BEAD_Rebu_Drivers.csv\")\n",
        "taxis_df = spark.read.option(\"header\", \"true\") \\\n",
        "                      .option(\"inferSchema\", \"true\")\\\n",
        "                      .option(\"multiline\", \"true\").json(\"/content/drive/My Drive/BEAD_DATA/BEAD_Rebu_TaxiCabs.json\")\n",
        "trip_data_df = spark.read.option(\"header\", \"true\").csv(\"/content/drive/MyDrive/BEAD_DATA/BEAD_Rebu_TripData.csv\")\n",
        "passenger_df = spark.read.option(\"header\", \"true\").csv(\"/content/drive/MyDrive/BEAD_DATA/BEAD_Rebu_Passengers.csv\")\n",
        "\n",
        "# Add a column Convert Trip Start Time to date format\n",
        "trip_data_df = trip_data_df.withColumn(\"TripDate\", to_date(trip_data_df[\"Date\"], 'd-MMM-yy'))\n",
        "\n",
        "# Add a column indicating if the day is a weekend or weekday\n",
        "trip_data_df = trip_data_df.withColumn(\"IsWeekend\", (dayofweek(trip_data_df.TripDate) == 1) | (dayofweek(trip_data_df.TripDate) == 7))\n",
        "\n",
        "# Filter for trips in January 2024 and calculate the average distance traveled\n",
        "jan_2024_trips = trip_data_df.filter((month(trip_data_df.TripDate) == 1) & (year(trip_data_df.TripDate) == 2024))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qN6z6AypQTr7"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A - Data retrieval using Spark SQL\n",
        "#===================================\n",
        "\n",
        "# 1. Retrieve all Driver data\n",
        "drivers_df.show()\n",
        "# 2. Retrieve all Taxis and display the data in ascending order of Taxi License Plate number\n",
        "taxis_df = taxis_df.orderBy(\"TaxiNumber\")\n",
        "taxis_df.show(taxis_df.count(),False)\n",
        "\n",
        "# 3. Retrieve all Limousine Taxis (Taxi Number, Taxi Type, Taxi Colour)\n",
        "limosine_taxis_df = taxis_df.select(\"TaxiNumber\", \"TaxiType\", \"TaxiColor\").where(\"TaxiType = 'Limosine'\")\n",
        "limosine_taxis_df.show(limosine_taxis_df.count(),False)\n",
        "\n",
        "# 4. Retrieve all 4-seater Premier taxis\n",
        "four_seater_taxi = taxis_df.where(\"TaxiType = 'Premier' AND TaxiPassengerCapacity = 4\")\n",
        "four_seater_taxi.show(four_seater_taxi.count(),False)\n",
        "\n",
        "print(f\"Total count of records in trip_data_df: {taxis_df.count()}\")\n",
        "print(f\"Total count of records in limosine_taxis_df: {limosine_taxis_df.count()}\")\n",
        "print(f\"Total count of records in four_seater_taxi: {four_seater_taxi.count()}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Cph2AIss3K22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# B - Aggregation and Statistical Queries\n",
        "#========================================\n",
        "# 5. Determine the average distance per trip based on ALL trips in the month of January 2024\n",
        "average_distance_jan = jan_2024_trips.agg(avg(\"Distance Travelled\").alias(\"AverageDistance\"))\n",
        "average_distance_jan.show()\n",
        "\n",
        "# 6 Filter for Maxi Cab trips and calculate the total fares collected\n",
        "total_fares_maxi_cab = trip_data_df.filter(trip_data_df[\"Taxi Type\"] == 'Maxi Cab') \\\n",
        "                                   .groupBy(\"Taxi Type\") \\\n",
        "                                   .agg(sum(\"Trip Fare\").alias(\"TotalFare\"))\n",
        "total_fares_maxi_cab.show()"
      ],
      "metadata": {
        "id": "qMTdviuZ3Ow0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C. Analytics\n",
        "#=============\n",
        "# 7 Filter for Standard Taxis and calculate the average occupancy\n",
        "average_occupancy = trip_data_df.filter(trip_data_df[\"Taxi Type\"] == 'Standard') \\\n",
        "                                .withColumn(\"Occupancy\", col(\"Number Of Passengers\") / col(\"Taxi Capacity\")) \\\n",
        "                                .agg(avg(\"Occupancy\").alias(\"AverageOccupancy\")).show()\n",
        "\n",
        "# 8. Filter for trips in January 2024 and calculate total fares collected by day of the week\n",
        "fares_by_day_of_week = jan_2024_trips.groupBy(\"Day\") \\\n",
        "                                   .agg(sum(\"Trip Fare\").alias(\"TotalFare\")).show()\n",
        "\n",
        "\n",
        "# 9 . Filter for trips in January 2024 and calculate total revenue by hour of the day and day of the week\n",
        "revenue_by_hour_day = jan_2024_trips.groupBy(\"Hour of Day\", \"Day\") \\\n",
        "                                  .agg(sum(\"Trip Fare\").alias(\"TotalRevenue\")) \\\n",
        "                                  .orderBy(\"Hour of Day\", \"Day\")\n",
        "revenue_by_hour_day.show()\n",
        "\n",
        "# 10. Filter for trips in January 2024 and count trips per day, grouping by weekends and weekdays\n",
        "trips_weekends_vs_weekdays = trip_data_df.groupBy(\"IsWeekend\") \\\n",
        "                                         .agg((count(\"*\") / countDistinct(\"Date\")).alias(\"AverageTripsPerDay\")).show()\n",
        "\n",
        "print(f\"Total count of records in Revenue by hour day: {revenue_by_hour_day.count()}\")"
      ],
      "metadata": {
        "id": "RRMcUjVe4JRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D Multiple Entities Joining and multiple formats joined in a DataFrame\n",
        "#========================================================================\n",
        "\n",
        "# Rename the CustomerId column to Passenger ID to match the trip data\n",
        "passenger_df = passenger_df.withColumnRenamed(\"PassengerID\", \"Passenger ID\")\n",
        "\n",
        "# joined_df = trip_data_df.join(customer_df, trip_data_df[\"Passenger ID\"] == customer_df[\"Passenger ID\"], \"inner\")\n",
        "joined_df = trip_data_df.join(passenger_df, \"Passenger ID\")\n",
        "\n",
        "# Filter for Gold Status Passengers in January 2024 and calculate total fares\n",
        "total_fares_gold = joined_df.filter((col(\"MemSilvererStGoldtus\") == \"Gold\") &\n",
        "                                    (month(joined_df.TripDate) == 1) &\n",
        "                                    (year(joined_df.TripDate) == 2024)) \\\n",
        "                            .agg(sum(\"Trip Fare\").alias(\"TotalFaresGold\"))\n",
        "\n",
        "# Calculate total fares for all passengers in January 2024\n",
        "total_fares_all = joined_df.filter((month(joined_df.TripDate) == 1) &\n",
        "                                   (year(joined_df.TripDate) == 2024)) \\\n",
        "                           .agg(sum(\"Trip Fare\").alias(\"TotalFaresAll\"))\n",
        "\n",
        "total_fares_gold_value = total_fares_gold.collect()[0][\"TotalFaresGold\"]\n",
        "total_fares_all_value = total_fares_all.collect()[0][\"TotalFaresAll\"]\n",
        "\n",
        "# Calculate the percentage\n",
        "percentage_gold = (total_fares_gold_value / total_fares_all_value) * 100\n",
        "\n",
        "print(f\"Total fares paid by Gold Status Passengers in January 2024: {total_fares_gold_value}\")\n",
        "print(f\"Percentage of total fares for all customers: {percentage_gold:.2f}%\")\n"
      ],
      "metadata": {
        "id": "PrcLrTwN_iAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}